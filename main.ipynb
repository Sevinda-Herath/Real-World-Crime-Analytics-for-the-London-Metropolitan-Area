{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aec8248",
   "metadata": {},
   "source": [
    "# Real-World Crime Analytics for the London Metropolitan Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ab0a5",
   "metadata": {},
   "source": [
    "## 1. Environment Setup (Linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c38644",
   "metadata": {},
   "source": [
    "### 1.1. Update Linux Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47639499",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63419ff",
   "metadata": {},
   "source": [
    "### 1.2. Install Python and Packages (pip & venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927465c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install -y python3 python3-pip python3-venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6849a40",
   "metadata": {},
   "source": [
    "### 1.3. Create a Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1342df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdf6d4",
   "metadata": {},
   "source": [
    "### 1.4. Activate the Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913b357",
   "metadata": {},
   "source": [
    "### 1.5. Install the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a912562",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693880e3",
   "metadata": {},
   "source": [
    "### 2.1. Create Folders to Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create datasets folder if it doesn't exist\n",
    "os.makedirs(\"Datasets\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Map-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Population-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e127f",
   "metadata": {},
   "source": [
    "### 2.2. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca29942",
   "metadata": {},
   "source": [
    "#### 2.2.1. Download Income Data - <a>www.ons.gov.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0605354",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx \"https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2020/saiefy1920finalqaddownload280923.xlsx\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2ab2b",
   "metadata": {},
   "source": [
    "#### 2.2.2. Download Population Data - <a>www.ons.gov.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9c0f2",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx \"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareamidyearpopulationestimates/mid2022revisednov2025tomid2024/sapelsoasyoa20222024.xlsx\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0e06d",
   "metadata": {},
   "source": [
    "#### 2.2.3. Download Police Data - <a>data.police.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Police-Data/RAW-POLICE-2022-10-TO-2025-09.zip \"https://data.police.uk/data/archive/2025-09.zip\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the police data zip file\n",
    "!unzip -o Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip -d Datasets/Raw-Data/Police-Data\n",
    "print(\"Extracted police data to Datasets/Raw-Data/Police-Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e717c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the zip file to save space\n",
    "!rm -rf Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842018a4",
   "metadata": {},
   "source": [
    "#### 2.2.4. Download Map Data - <a>geoportal.statistics.gov.uk</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bfb66",
   "metadata": {},
   "source": [
    "#### Note: Map Data from ONS Geography Can't be Downloaded Directly, So Use the Below Links to Download Them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b202dc",
   "metadata": {},
   "source": [
    "1. LSOAs - <a>https://geoportal.statistics.gov.uk/datasets/ons::output-areas-december-2021-boundaries-ew-bgc-v2/about</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f4ce8",
   "metadata": {},
   "source": [
    "2. MSOAs - <a>https://geoportal.statistics.gov.uk/datasets/ons::middle-layer-super-output-areas-december-2021-boundaries-ew-bfc-v7-2/about</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528256c3",
   "metadata": {},
   "source": [
    "### 2.3. Converting File Types and Keeping Necessary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a2613",
   "metadata": {},
   "source": [
    "#### 2.3.1. Convert XLSX (Excel) files to CSV using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Safe filename from sheet name\n",
    "def sanitize(name: str) -> str:\n",
    "    # Replace non-alphanumeric with underscores, strip, collapse repeats\n",
    "    name = re.sub(r\"[^A-Za-z0-9]+\", \"_\", name).strip(\"_\")\n",
    "    return re.sub(r\"_+\", \"_\", name) or \"Sheet\"\n",
    "\n",
    "# Convert Income-MSOA.xlsx: write one CSV per sheet\n",
    "income_xlsx_path = \"Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx\"\n",
    "income_out_dir = \"Datasets/Raw-Data/Income-Data/Income-MSOA\"\n",
    "os.makedirs(income_out_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    xls_income = pd.ExcelFile(income_xlsx_path)\n",
    "    for sheet in xls_income.sheet_names:\n",
    "        df = pd.read_excel(xls_income, sheet_name=sheet)\n",
    "        safe = sanitize(sheet)\n",
    "        out_path = os.path.join(income_out_dir, f\"Income-MSOA-{safe}.csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "    print(f\"Exported {len(xls_income.sheet_names)} sheets from {income_xlsx_path} to {income_out_dir}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to process income workbook:\", e)\n",
    "\n",
    "# Convert Population-LSOA.xlsx: write one CSV per sheet\n",
    "population_xlsx_path = \"Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx\"\n",
    "population_out_dir = \"Datasets/Raw-Data/Population-Data/Population-LSOA\"\n",
    "os.makedirs(population_out_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    xls_pop = pd.ExcelFile(population_xlsx_path)\n",
    "    for sheet in xls_pop.sheet_names:\n",
    "        df = pd.read_excel(xls_pop, sheet_name=sheet)\n",
    "        safe = sanitize(sheet)\n",
    "        out_path = os.path.join(population_out_dir, f\"Population-LSOA-{safe}.csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "    print(f\"Exported {len(xls_pop.sheet_names)} sheets from {population_xlsx_path} to {population_out_dir}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to process population workbook:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8174e5a",
   "metadata": {},
   "source": [
    "#### 2.3.2. Retain Only Metropolitan Police Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "police_root = Path(\"Datasets/Raw-Data/Police-Data\")\n",
    "date_range = (\"2022-10\", \"2025-09\")\n",
    "keep_token = \"metropolitan\"\n",
    "\n",
    "if not police_root.exists():\n",
    "    raise FileNotFoundError(f\"Missing directory: {police_root}\")\n",
    "\n",
    "kept: List[Path] = []\n",
    "removed: List[Path] = []\n",
    "\n",
    "# Delete every police file that does not belong to the Metropolitan force.\n",
    "for file_path in police_root.rglob(\"*\"):\n",
    "    if not file_path.is_file():\n",
    "        continue\n",
    "    if keep_token in file_path.name.lower():\n",
    "        kept.append(file_path)\n",
    "        continue\n",
    "    file_path.unlink()\n",
    "    removed.append(file_path)\n",
    "\n",
    "print(f\"Date Range - {date_range[0]} - {date_range[1]}\")\n",
    "for path in sorted(kept):\n",
    "    print(path)\n",
    "\n",
    "print(f\"Removed {len(removed)} other files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb473fd",
   "metadata": {},
   "source": [
    "### 2.4. Copy Only the Necessary Files for Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Datasets/Data-for-Cleaning\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Population-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Map-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744910f7",
   "metadata": {},
   "source": [
    "#### 2.4.1. Copy Police Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3189340",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Police-Data/* Datasets/Data-for-Cleaning/Police-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10987c",
   "metadata": {},
   "source": [
    "#### 2.4.2. Copy Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Map-Data/* Datasets/Data-for-Cleaning/Map-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cefa68",
   "metadata": {},
   "source": [
    "#### 2.4.3. Copy Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db826658",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Income-Data/Income-MSOA/Income-MSOA-Total_annual_income.csv Datasets/Data-for-Cleaning/Income-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78933704",
   "metadata": {},
   "source": [
    "#### 2.4.4. Copy Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2022_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/\n",
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2023_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/\n",
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2024_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2fb02",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bbe190",
   "metadata": {},
   "source": [
    "### 3. 1. Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize Spark\n",
    "import pyspark\n",
    "from pathlib import Path\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "\n",
    "# Initialize session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Real-World Crime Analytics for the London Metropolitan Area\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7210f6b",
   "metadata": {},
   "source": [
    "### 3. 2. Cleaning Income Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3756db",
   "metadata": {},
   "source": [
    "#### 3.2.1.  Reading the Income Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e261173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the total annual income data\n",
    "total_income_path = \"Datasets/Data-for-Cleaning/Income-Data/Income-MSOA-Total_annual_income.csv\"\n",
    "\n",
    "total_income_df = spark.read.option(\"header\", \"true\").csv(total_income_path)\n",
    "\n",
    "total_income_df.show(5)\n",
    "total_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa96a03",
   "metadata": {},
   "source": [
    "#### 3.2.2.  Remove Extra Header Lines and Load Cleaned Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read as text so we can inspect the actual first lines\n",
    "raw = spark.read.text(total_income_path)\n",
    "\n",
    "# Drop the first 4 lines\n",
    "clean_lines = raw.rdd.zipWithIndex() \\\n",
    "    .filter(lambda x: x[1] >= 4) \\\n",
    "    .map(lambda x: x[0].value)\n",
    "\n",
    "# Convert back to CSV DataFrame\n",
    "clean_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(clean_lines)\n",
    "\n",
    "total_income_df = clean_df\n",
    "\n",
    "total_income_df.show(5)\n",
    "total_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcb379",
   "metadata": {},
   "source": [
    "#### 3.2.3. Summary Statistics for Cleaned Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d82df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cf760",
   "metadata": {},
   "source": [
    "#### 3.2.4. Detecting Duplicate Rows in Cleaned Income Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = total_income_df.groupBy(total_income_df.columns) \\\n",
    "               .count() \\\n",
    "               .filter(\"count > 1\")\n",
    "\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3117171",
   "metadata": {},
   "source": [
    "### 3. 3. Cleaning Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822f98d",
   "metadata": {},
   "source": [
    "#### 3.3.1.  Reading the Population Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611de598",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_paths = {\n",
    "    \"2022\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2022_LSOA_2021.csv\",\n",
    "    \"2023\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2023_LSOA_2021.csv\",\n",
    "    \"2024\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2024_LSOA_2021.csv\",\n",
    "}\n",
    "\n",
    "population_dfs = {}\n",
    "for year, path in population_paths.items():\n",
    "    df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "    population_dfs[year] = df\n",
    "    print(f\"Population {year} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()\n",
    "\n",
    "population_2022_df = population_dfs[\"2022\"]\n",
    "population_2023_df = population_dfs[\"2023\"]\n",
    "population_2024_df = population_dfs[\"2024\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4125dba",
   "metadata": {},
   "source": [
    "#### 3.3.2.  Remove Extra Header Lines and Load Cleaned Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_population(path: str):\n",
    "    rows = spark.read.text(path)\n",
    "    trimmed = rows.rdd.zipWithIndex().filter(lambda x: x[1] >= 3).map(lambda x: x[0].value)\n",
    "    return spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(trimmed)\n",
    "\n",
    "population_clean = {year: clean_population(path) for year, path in population_paths.items()}\n",
    "\n",
    "population_2022_df = population_clean[\"2022\"]\n",
    "population_2023_df = population_clean[\"2023\"]\n",
    "population_2024_df = population_clean[\"2024\"]\n",
    "\n",
    "for year, df in population_clean.items():\n",
    "    print(f\"Cleaned Population {year} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b2796",
   "metadata": {},
   "source": [
    "#### 3.3.3. Summary Statistics for Cleaned Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Population 2022 Data:\")\n",
    "population_2022_df.describe().show()\n",
    "\n",
    "print(\"Population 2023 Data:\")\n",
    "population_2023_df.describe().show()\n",
    "\n",
    "print(\"Population 2024 Data:\")\n",
    "population_2024_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8c80e",
   "metadata": {},
   "source": [
    "#### 3.3.4. Detecting Duplicate Rows in Cleaned Population Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = {\n",
    "    year: df.groupBy(*df.columns).count().filter(\"count > 1\")\n",
    "    for year, df in population_clean.items()\n",
    "}\n",
    "\n",
    "duplicates_2022 = duplicates[\"2022\"]\n",
    "duplicates_2023 = duplicates[\"2023\"]\n",
    "duplicates_2024 = duplicates[\"2024\"]\n",
    "\n",
    "for year, dup_df in duplicates.items():\n",
    "    print(f\"Duplicate Rows in Population {year} Data:\")\n",
    "    dup_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c331bf",
   "metadata": {},
   "source": [
    "### 3. 4. Cleaning Map Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c02b2d",
   "metadata": {},
   "source": [
    "#### 3.4.1.  Reading the Map Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the population datasets\n",
    "map_paths = {\n",
    "    \"lsoa\": \"Datasets/Data-for-Cleaning/Map-Data/Map-LSOA-2021.csv\",\n",
    "    \"msoa\": \"Datasets/Data-for-Cleaning/Map-Data/Map-MSOA-2021.csv\",\n",
    "}\n",
    "\n",
    "map_dfs = {}\n",
    "for map, path in map_paths.items():\n",
    "    df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "    map_dfs[map] = df\n",
    "    print(f\"Population {map} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()\n",
    "\n",
    "map_lsoa_df = map_dfs[\"lsoa\"]\n",
    "map_msoa_df = map_dfs[\"msoa\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dacf18",
   "metadata": {},
   "source": [
    "#### 3.4.2. Summary Statistics for Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Map LSOA Data:\")\n",
    "map_lsoa_df.describe().show()\n",
    "\n",
    "print(\"Map MSOA Data:\")\n",
    "map_msoa_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54648ebb",
   "metadata": {},
   "source": [
    "#### 3.4.3. Detecting Duplicate Rows in Map Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a59de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_map = {\n",
    "    \"lsoa\": map_lsoa_df.groupBy(*map_lsoa_df.columns).count().filter(\"count > 1\"),\n",
    "    \"msoa\": map_msoa_df.groupBy(*map_msoa_df.columns).count().filter(\"count > 1\"),\n",
    "}\n",
    "\n",
    "duplicates_lsoa = duplicates_map[\"lsoa\"]\n",
    "duplicates_msoa = duplicates_map[\"msoa\"]\n",
    "\n",
    "for map_type, dup_df in duplicates_map.items():\n",
    "    print(f\"Duplicate Rows in Map {map_type.upper()} Data:\")\n",
    "    dup_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68e16b",
   "metadata": {},
   "source": [
    "### 3. 5. Cleaning Police Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33664a",
   "metadata": {},
   "source": [
    "#### 3.5.1. Combine All Police data into a Single Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "police_data_root = Path(\"Datasets/Data-for-Cleaning/Police-Data\")\n",
    "\n",
    "def load_police_dataset(file_glob: str) -> DataFrame:\n",
    "    \"\"\"Load all monthly police CSVs matching the glob into a single DataFrame.\"\"\"\n",
    "    # Gather every CSV matching the pattern across the month folders.\n",
    "    matches = sorted(police_data_root.rglob(file_glob))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No police files matched pattern: {file_glob}\")\n",
    "    print(f\"Matched {len(matches)} files for pattern '{file_glob}'\")\n",
    "    # Load all matched files into a single Spark DataFrame.\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv([str(path) for path in matches])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Build combined DataFrames for each police dataset family.\n",
    "police_outcomes_df = load_police_dataset(\"*-metropolitan-outcomes.csv\")\n",
    "police_stop_search_df = load_police_dataset(\"*-metropolitan-stop-and-search.csv\")\n",
    "police_street_df = load_police_dataset(\"*-metropolitan-street.csv\")\n",
    "\n",
    "# Register temp views for downstream Spark SQL operations.\n",
    "police_outcomes_df.createOrReplaceTempView(\"police_outcomes\")\n",
    "police_stop_search_df.createOrReplaceTempView(\"police_stop_and_search\")\n",
    "police_street_df.createOrReplaceTempView(\"police_street\")\n",
    "\n",
    "# Print simple row counts for a quick sanity check.\n",
    "print(\"Combined police outcomes rows:\", police_outcomes_df.count())\n",
    "print(\"Combined police stop and search rows:\", police_stop_search_df.count())\n",
    "print(\"Combined police street rows:\", police_street_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b5cb4",
   "metadata": {},
   "source": [
    "#### 3.5.2. Police Outcomes Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47d242",
   "metadata": {},
   "source": [
    "##### 3.5.2.1. Police Outcomes Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Outcomes Schema:\")\n",
    "police_outcomes_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2a3ce",
   "metadata": {},
   "source": [
    "##### 3.5.2.2. Police Outcomes Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_outcomes_df.orderBy(\"Month\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_outcomes_df.orderBy(\"Month\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f545a3",
   "metadata": {},
   "source": [
    "##### 3.5.2.3. Police Outcomes Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_outcomes_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a2a8d",
   "metadata": {},
   "source": [
    "##### 3.5.2.4. Fill missing coordinates with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_outcomes_df with None\n",
    "police_outcomes_df = police_outcomes_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_outcomes = [\n",
    "    f.name for f in police_outcomes_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_outcomes:\n",
    "    police_outcomes_df = police_outcomes_df.fillna(0.0, subset=numeric_cols_outcomes)\n",
    "\n",
    "police_outcomes_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6de0a3",
   "metadata": {},
   "source": [
    "#### 3.5.3. Police Stop and Search Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c866e9",
   "metadata": {},
   "source": [
    "##### 3.5.3.1. Police Stop and Search Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Stop and Search Schema:\")\n",
    "police_stop_search_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0820c9",
   "metadata": {},
   "source": [
    "##### 3.5.3.2. Police Stop and Search Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7056b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_stop_search_df.orderBy(\"Date\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_stop_search_df.orderBy(\"Date\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d711b",
   "metadata": {},
   "source": [
    "##### 3.5.3.3. Police Stop and Search Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_stop_search_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc3519",
   "metadata": {},
   "source": [
    "##### 3.5.3.4. Fill missing coordinates with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa306f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_stop_search_df with None\n",
    "police_stop_search_df = police_stop_search_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_stop = [\n",
    "    f.name for f in police_stop_search_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_stop:\n",
    "    police_stop_search_df = police_stop_search_df.fillna(0.0, subset=numeric_cols_stop)\n",
    "\n",
    "police_stop_search_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7f1d3",
   "metadata": {},
   "source": [
    "#### 3.5.4. Police Street Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7b8a5",
   "metadata": {},
   "source": [
    "##### 3.5.4.1. Police Street Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Stop and Search Schema:\")\n",
    "police_street_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b95ee",
   "metadata": {},
   "source": [
    "##### 3.5.4.2. Police Street Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_street_df.orderBy(\"Month\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_street_df.orderBy(\"Month\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28343cf",
   "metadata": {},
   "source": [
    "##### 3.5.4.3. Police Street Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_street_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbf8ba",
   "metadata": {},
   "source": [
    "##### 3.5.4.4. Fill missing coordinates with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_street_df with None\n",
    "police_street_df = police_street_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_street = [\n",
    "    f.name for f in police_street_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_street:\n",
    "    police_street_df = police_street_df.fillna(0.0, subset=numeric_cols_street)\n",
    "\n",
    "police_street_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28eaa9f",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095b53c",
   "metadata": {},
   "source": [
    "### 4.0. Create Folders for Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Datasets/Cleaned-Data/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Population-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Map-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff9e87",
   "metadata": {},
   "source": [
    "### 4.1. Transform Cleaned Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d67c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa2db3",
   "metadata": {},
   "source": [
    "#### 4.1.1. Select only the required columns from clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80256bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df = total_income_df.select(\n",
    "    \"MSOA code\",\n",
    "    \"MSOA name\",\n",
    "    \"Total annual income (Â£)\"\n",
    ")\n",
    "\n",
    "selected_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50954384",
   "metadata": {},
   "source": [
    "#### 4.1.2. Standardize Colomn Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_income_df = simplify_column_names(selected_income_df)\n",
    "selected_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622024d3",
   "metadata": {},
   "source": [
    "#### 4.1.3. Verify Income Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667f30b",
   "metadata": {},
   "source": [
    "#### 4.1.3. Save the cleaned income data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1875a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Income-Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec819ae1",
   "metadata": {},
   "source": [
    "### 4.2. Transform Cleaned Population Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd644e0f",
   "metadata": {},
   "source": [
    "#### 4.2.1. Display the Population DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2022_df.show(5)\n",
    "population_2023_df.show(5)\n",
    "population_2024_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd92b4",
   "metadata": {},
   "source": [
    "#### 4.2.2. Select Required Columns from Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_population_columns(population_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return population_df.select(\n",
    "        \"LSOA 2021 Code\",\n",
    "        \"LSOA 2021 Name\",\n",
    "        \"Total\"\n",
    "\n",
    "    )\n",
    "\n",
    "selected_population_2022_df = select_population_columns(population_2022_df)\n",
    "selected_population_2023_df = select_population_columns(population_2023_df)\n",
    "selected_population_2024_df = select_population_columns(population_2024_df)\n",
    "\n",
    "selected_population_2022_df.show(5)\n",
    "selected_population_2023_df.show(5)\n",
    "selected_population_2024_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d118dc",
   "metadata": {},
   "source": [
    "#### 4.2.3. Standardize Population Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_population_2022_df = simplify_column_names(selected_population_2022_df)\n",
    "selected_population_2022_df.show(5)\n",
    "\n",
    "selected_population_2023_df = simplify_column_names(selected_population_2023_df)\n",
    "selected_population_2023_df.show(5)\n",
    "\n",
    "selected_population_2024_df = simplify_column_names(selected_population_2024_df)\n",
    "selected_population_2024_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10cd90",
   "metadata": {},
   "source": [
    "#### 4.2.4. Verify Population Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_population_2022_df.printSchema()\n",
    "selected_population_2023_df.printSchema()\n",
    "selected_population_2024_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f412ef7",
   "metadata": {},
   "source": [
    "#### 4.2.5. Save Cleaned Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "selected_population_2022_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2022\")\n",
    "selected_population_2023_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2023\")\n",
    "selected_population_2024_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32d0f4",
   "metadata": {},
   "source": [
    "### 4.3. Transform Cleaned Map Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f77175",
   "metadata": {},
   "source": [
    "#### 4.3.1. Display the Map DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f509fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lsoa_df.show(5)\n",
    "map_msoa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100337e6",
   "metadata": {},
   "source": [
    "#### 4.3.2. Select Required Columns from LSOA Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381825f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lsoa_columns(map_lsoa_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return map_lsoa_df.select(\n",
    "        \"LSOA21CD\",\n",
    "        \"LSOA21NM\",\n",
    "        \"LAT\",\n",
    "        \"LONG\"\n",
    "    )\n",
    "\n",
    "selected_map_lsoa_df = select_lsoa_columns(map_lsoa_df)\n",
    "\n",
    "selected_map_lsoa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d615fd",
   "metadata": {},
   "source": [
    "#### 4.3.3. Select Required Columns from MSOA Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_msoa_columns(map_msoa_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return map_msoa_df.select(\n",
    "        \"MSOA21CD\",\n",
    "        \"MSOA21NM\",\n",
    "        \"LAT\",\n",
    "        \"LONG\"\n",
    "    )\n",
    "\n",
    "selected_map_msoa_df = select_msoa_columns(map_msoa_df)\n",
    "\n",
    "selected_map_msoa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5adeb",
   "metadata": {},
   "source": [
    "#### 4.3.4. Standardize Map Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_map_lsoa_df = simplify_column_names(selected_map_lsoa_df)\n",
    "selected_map_lsoa_df.show(5)\n",
    "\n",
    "selected_map_msoa_df = simplify_column_names(selected_map_msoa_df)\n",
    "selected_map_msoa_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81d1ff",
   "metadata": {},
   "source": [
    "#### 4.3.5. Verify Map Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_map_lsoa_df.printSchema()\n",
    "selected_map_msoa_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9841e0d",
   "metadata": {},
   "source": [
    "#### 4.3.6. Save Cleaned Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "selected_map_lsoa_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Map-Data/lsoa\")\n",
    "selected_map_msoa_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Map-Data/msoa\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c8880",
   "metadata": {},
   "source": [
    "### 4.4. Transform Cleaned Police Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a317273",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_outcomes_df.show(5)\n",
    "police_stop_search_df.show(5)\n",
    "police_street_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1682e",
   "metadata": {},
   "source": [
    "#### 4.4.1. Display the Police DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "police_outcomes_df = simplify_column_names(police_outcomes_df)\n",
    "police_outcomes_df.show(5)\n",
    "\n",
    "police_stop_search_df = simplify_column_names(police_stop_search_df)\n",
    "police_stop_search_df.show(5)\n",
    "\n",
    "police_street_df = simplify_column_names(police_street_df)\n",
    "police_street_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0223",
   "metadata": {},
   "source": [
    "#### 4.4.2. Standardize Police Data Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab46335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "# police_stop_search_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/stop-search\")\n",
    "# police_outcomes_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/outcomes\")\n",
    "# police_street_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/street\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6e0aa",
   "metadata": {},
   "source": [
    "#### 4.4.3. Save Police Data as CSV (Commented Out - Using Parquet Instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62230e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stop & search data as Parquet\n",
    "police_stop_search_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/stop-search-parquet\")\n",
    "\n",
    "# Save outcomes data as Parquet\n",
    "police_outcomes_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/outcomes-parquet\")\n",
    "\n",
    "# Save street data as Parquet\n",
    "police_street_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/street-parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119baca",
   "metadata": {},
   "source": [
    "#### 4.4.4. Save Police Data as Parquet with Snappy Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9003f6",
   "metadata": {},
   "source": [
    "## 5. Data Querying"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
