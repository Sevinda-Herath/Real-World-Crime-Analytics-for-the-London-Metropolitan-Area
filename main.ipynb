{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aec8248",
   "metadata": {},
   "source": [
    "# Real-World Crime Analytics for the London Metropolitan Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ab0a5",
   "metadata": {},
   "source": [
    "## 1. Environment Setup (Linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c38644",
   "metadata": {},
   "source": [
    "### 1.1. Update Linux Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47639499",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63419ff",
   "metadata": {},
   "source": [
    "### 1.2. Install Python and Packages (pip & venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927465c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install -y python3 python3-pip python3-venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6849a40",
   "metadata": {},
   "source": [
    "### 1.3. Create a Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1342df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdf6d4",
   "metadata": {},
   "source": [
    "### 1.4. Activate the Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913b357",
   "metadata": {},
   "source": [
    "### 1.5. Install the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a912562",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693880e3",
   "metadata": {},
   "source": [
    "### 2.1. Create Folders to Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create datasets folder if it doesn't exist\n",
    "os.makedirs(\"Datasets\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Map-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Raw-Data/Population-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e127f",
   "metadata": {},
   "source": [
    "### 2.2. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca29942",
   "metadata": {},
   "source": [
    "#### 2.2.1. Download Income Data - <a>www.ons.gov.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0605354",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx \"https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales/financialyearending2020/saiefy1920finalqaddownload280923.xlsx\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2ab2b",
   "metadata": {},
   "source": [
    "#### 2.2.2. Download Population Data - <a>www.ons.gov.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9c0f2",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx \"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareamidyearpopulationestimates/mid2022revisednov2025tomid2024/sapelsoasyoa20222024.xlsx\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0e06d",
   "metadata": {},
   "source": [
    "#### 2.2.3. Download Police Data - <a>data.police.uk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Datasets/Raw-Data/Police-Data/RAW-POLICE-2022-10-TO-2025-09.zip \"https://data.police.uk/data/archive/2025-09.zip\"\n",
    "print(\"Downloaded to Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the police data zip file\n",
    "!unzip -o Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip -d Datasets/Raw-Data/Police-Data\n",
    "print(\"Extracted police data to Datasets/Raw-Data/Police-Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e717c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the zip file to save space\n",
    "!rm -rf Datasets/Raw-Data/RAW-POLICE-2022-10-TO-2025-09.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842018a4",
   "metadata": {},
   "source": [
    "#### 2.2.4. Download Map Data - <a>geoportal.statistics.gov.uk</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bfb66",
   "metadata": {},
   "source": [
    "#### Note: Map Data from ONS Geography Can't be Downloaded Directly, So Use the Below Links to Download Them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b202dc",
   "metadata": {},
   "source": [
    "1. LSOAs - <a>https://geoportal.statistics.gov.uk/datasets/ons::output-areas-december-2021-boundaries-ew-bgc-v2/about</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f4ce8",
   "metadata": {},
   "source": [
    "2. MSOAs - <a>https://geoportal.statistics.gov.uk/datasets/ons::middle-layer-super-output-areas-december-2021-boundaries-ew-bfc-v7-2/about</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528256c3",
   "metadata": {},
   "source": [
    "### 2.3. Converting File Types and Keeping Necessary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a2613",
   "metadata": {},
   "source": [
    "#### 2.3.1. Convert XLSX (Excel) files to CSV using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Safe filename from sheet name\n",
    "def sanitize(name: str) -> str:\n",
    "    # Replace non-alphanumeric with underscores, strip, collapse repeats\n",
    "    name = re.sub(r\"[^A-Za-z0-9]+\", \"_\", name).strip(\"_\")\n",
    "    return re.sub(r\"_+\", \"_\", name) or \"Sheet\"\n",
    "\n",
    "# Convert Income-MSOA.xlsx: write one CSV per sheet\n",
    "income_xlsx_path = \"Datasets/Raw-Data/Income-Data/Income-MSOA.xlsx\"\n",
    "income_out_dir = \"Datasets/Raw-Data/Income-Data/Income-MSOA\"\n",
    "os.makedirs(income_out_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    xls_income = pd.ExcelFile(income_xlsx_path)\n",
    "    for sheet in xls_income.sheet_names:\n",
    "        df = pd.read_excel(xls_income, sheet_name=sheet)\n",
    "        safe = sanitize(sheet)\n",
    "        out_path = os.path.join(income_out_dir, f\"Income-MSOA-{safe}.csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "    print(f\"Exported {len(xls_income.sheet_names)} sheets from {income_xlsx_path} to {income_out_dir}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to process income workbook:\", e)\n",
    "\n",
    "# Convert Population-LSOA.xlsx: write one CSV per sheet\n",
    "population_xlsx_path = \"Datasets/Raw-Data/Population-Data/Population-LSOA.xlsx\"\n",
    "population_out_dir = \"Datasets/Raw-Data/Population-Data/Population-LSOA\"\n",
    "os.makedirs(population_out_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    xls_pop = pd.ExcelFile(population_xlsx_path)\n",
    "    for sheet in xls_pop.sheet_names:\n",
    "        df = pd.read_excel(xls_pop, sheet_name=sheet)\n",
    "        safe = sanitize(sheet)\n",
    "        out_path = os.path.join(population_out_dir, f\"Population-LSOA-{safe}.csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "    print(f\"Exported {len(xls_pop.sheet_names)} sheets from {population_xlsx_path} to {population_out_dir}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to process population workbook:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8174e5a",
   "metadata": {},
   "source": [
    "#### 2.3.2. Retain Only Metropolitan Police Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "police_root = Path(\"Datasets/Raw-Data/Police-Data\")\n",
    "date_range = (\"2022-10\", \"2025-09\")\n",
    "keep_token = \"metropolitan\"\n",
    "\n",
    "if not police_root.exists():\n",
    "    raise FileNotFoundError(f\"Missing directory: {police_root}\")\n",
    "\n",
    "kept: List[Path] = []\n",
    "removed: List[Path] = []\n",
    "\n",
    "# Delete every police file that does not belong to the Metropolitan force.\n",
    "for file_path in police_root.rglob(\"*\"):\n",
    "    if not file_path.is_file():\n",
    "        continue\n",
    "    if keep_token in file_path.name.lower():\n",
    "        kept.append(file_path)\n",
    "        continue\n",
    "    file_path.unlink()\n",
    "    removed.append(file_path)\n",
    "\n",
    "print(f\"Date Range - {date_range[0]} - {date_range[1]}\")\n",
    "for path in sorted(kept):\n",
    "    print(path)\n",
    "\n",
    "print(f\"Removed {len(removed)} other files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb473fd",
   "metadata": {},
   "source": [
    "### 2.4. Copy Only the Necessary Files for Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Datasets/Data-for-Cleaning\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Population-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Data-for-Cleaning/Map-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744910f7",
   "metadata": {},
   "source": [
    "#### 2.4.1. Copy Police Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3189340",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Police-Data/* Datasets/Data-for-Cleaning/Police-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10987c",
   "metadata": {},
   "source": [
    "#### 2.4.2. Copy Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Map-Data/* Datasets/Data-for-Cleaning/Map-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cefa68",
   "metadata": {},
   "source": [
    "#### 2.4.3. Copy Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db826658",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Income-Data/Income-MSOA/Income-MSOA-Total_annual_income.csv Datasets/Data-for-Cleaning/Income-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78933704",
   "metadata": {},
   "source": [
    "#### 2.4.4. Copy Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2022_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/\n",
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2023_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/\n",
    "!cp -r Datasets/Raw-Data/Population-Data/Population-LSOA/Population-LSOA-Mid_2024_LSOA_2021.csv Datasets/Data-for-Cleaning/Population-Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2fb02",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bbe190",
   "metadata": {},
   "source": [
    "### 3. 1. Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize Spark\n",
    "import pyspark\n",
    "from pathlib import Path\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "\n",
    "# Initialize session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Real-World Crime Analytics for the London Metropolitan Area\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7210f6b",
   "metadata": {},
   "source": [
    "### 3. 2. Cleaning Income Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3756db",
   "metadata": {},
   "source": [
    "#### 3.2.1.  Reading the Income Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e261173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the total annual income data\n",
    "total_income_path = \"Datasets/Data-for-Cleaning/Income-Data/Income-MSOA-Total_annual_income.csv\"\n",
    "\n",
    "total_income_df = spark.read.option(\"header\", \"true\").csv(total_income_path)\n",
    "\n",
    "total_income_df.show(5)\n",
    "total_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa96a03",
   "metadata": {},
   "source": [
    "#### 3.2.2.  Remove Extra Header Lines - Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read as text so we can inspect the actual first lines\n",
    "raw = spark.read.text(total_income_path)\n",
    "\n",
    "# Drop the first 4 lines\n",
    "clean_lines = raw.rdd.zipWithIndex() \\\n",
    "    .filter(lambda x: x[1] >= 4) \\\n",
    "    .map(lambda x: x[0].value)\n",
    "\n",
    "# Convert back to CSV DataFrame\n",
    "clean_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(clean_lines)\n",
    "\n",
    "total_income_df = clean_df\n",
    "\n",
    "total_income_df.show(5)\n",
    "total_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcb379",
   "metadata": {},
   "source": [
    "#### 3.2.3. Summary Statistics for Cleaned Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d82df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cf760",
   "metadata": {},
   "source": [
    "#### 3.2.4. Detecting Duplicate Rows in Cleaned Income Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = total_income_df.groupBy(total_income_df.columns) \\\n",
    "               .count() \\\n",
    "               .filter(\"count > 1\")\n",
    "\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3117171",
   "metadata": {},
   "source": [
    "### 3. 3. Cleaning Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822f98d",
   "metadata": {},
   "source": [
    "#### 3.3.1.  Reading the Population Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611de598",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_paths = {\n",
    "    \"2022\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2022_LSOA_2021.csv\",\n",
    "    \"2023\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2023_LSOA_2021.csv\",\n",
    "    \"2024\": \"Datasets/Data-for-Cleaning/Population-Data/Population-LSOA-Mid_2024_LSOA_2021.csv\",\n",
    "}\n",
    "\n",
    "population_dfs = {}\n",
    "for year, path in population_paths.items():\n",
    "    df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "    population_dfs[year] = df\n",
    "    print(f\"Population {year} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()\n",
    "\n",
    "population_2022_df = population_dfs[\"2022\"]\n",
    "population_2023_df = population_dfs[\"2023\"]\n",
    "population_2024_df = population_dfs[\"2024\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4125dba",
   "metadata": {},
   "source": [
    "#### 3.3.2.  Remove Extra Header Lines - Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_population(path: str):\n",
    "    rows = spark.read.text(path)\n",
    "    trimmed = rows.rdd.zipWithIndex().filter(lambda x: x[1] >= 3).map(lambda x: x[0].value)\n",
    "    return spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(trimmed)\n",
    "\n",
    "population_clean = {year: clean_population(path) for year, path in population_paths.items()}\n",
    "\n",
    "population_2022_df = population_clean[\"2022\"]\n",
    "population_2023_df = population_clean[\"2023\"]\n",
    "population_2024_df = population_clean[\"2024\"]\n",
    "\n",
    "for year, df in population_clean.items():\n",
    "    print(f\"Cleaned Population {year} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b2796",
   "metadata": {},
   "source": [
    "#### 3.3.3. Summary Statistics for Cleaned Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Population 2022 Data:\")\n",
    "population_2022_df.describe().show()\n",
    "\n",
    "print(\"Population 2023 Data:\")\n",
    "population_2023_df.describe().show()\n",
    "\n",
    "print(\"Population 2024 Data:\")\n",
    "population_2024_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8c80e",
   "metadata": {},
   "source": [
    "#### 3.3.4. Detecting Duplicate Rows in Cleaned Population Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = {\n",
    "    year: df.groupBy(*df.columns).count().filter(\"count > 1\")\n",
    "    for year, df in population_clean.items()\n",
    "}\n",
    "\n",
    "duplicates_2022 = duplicates[\"2022\"]\n",
    "duplicates_2023 = duplicates[\"2023\"]\n",
    "duplicates_2024 = duplicates[\"2024\"]\n",
    "\n",
    "for year, dup_df in duplicates.items():\n",
    "    print(f\"Duplicate Rows in Population {year} Data:\")\n",
    "    dup_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c331bf",
   "metadata": {},
   "source": [
    "### 3. 4. Cleaning Map Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c02b2d",
   "metadata": {},
   "source": [
    "#### 3.4.1.  Reading the Map Data - Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the population datasets\n",
    "map_paths = {\n",
    "    \"lsoa\": \"Datasets/Data-for-Cleaning/Map-Data/Map-LSOA-2021.csv\",\n",
    "    \"msoa\": \"Datasets/Data-for-Cleaning/Map-Data/Map-MSOA-2021.csv\",\n",
    "}\n",
    "\n",
    "map_dfs = {}\n",
    "for map, path in map_paths.items():\n",
    "    df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "    map_dfs[map] = df\n",
    "    print(f\"Population {map} Data:\")\n",
    "    df.show(5)\n",
    "    df.printSchema()\n",
    "\n",
    "map_lsoa_df = map_dfs[\"lsoa\"]\n",
    "map_msoa_df = map_dfs[\"msoa\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dacf18",
   "metadata": {},
   "source": [
    "#### 3.4.2. Summary Statistics for Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Map LSOA Data:\")\n",
    "map_lsoa_df.describe().show()\n",
    "\n",
    "print(\"Map MSOA Data:\")\n",
    "map_msoa_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54648ebb",
   "metadata": {},
   "source": [
    "#### 3.4.3. Detecting Duplicate Rows in Map Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a59de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_map = {\n",
    "    \"lsoa\": map_lsoa_df.groupBy(*map_lsoa_df.columns).count().filter(\"count > 1\"),\n",
    "    \"msoa\": map_msoa_df.groupBy(*map_msoa_df.columns).count().filter(\"count > 1\"),\n",
    "}\n",
    "\n",
    "duplicates_lsoa = duplicates_map[\"lsoa\"]\n",
    "duplicates_msoa = duplicates_map[\"msoa\"]\n",
    "\n",
    "for map_type, dup_df in duplicates_map.items():\n",
    "    print(f\"Duplicate Rows in Map {map_type.upper()} Data:\")\n",
    "    dup_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68e16b",
   "metadata": {},
   "source": [
    "### 3. 5. Cleaning Police Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33664a",
   "metadata": {},
   "source": [
    "#### 3.5.1. Combine All Police data into a Single Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "police_data_root = Path(\"Datasets/Data-for-Cleaning/Police-Data\")\n",
    "\n",
    "def load_police_dataset(file_glob: str) -> DataFrame:\n",
    "    \"\"\"Load all monthly police CSVs matching the glob into a single DataFrame.\"\"\"\n",
    "    # Gather every CSV matching the pattern across the month folders.\n",
    "    matches = sorted(police_data_root.rglob(file_glob))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No police files matched pattern: {file_glob}\")\n",
    "    print(f\"Matched {len(matches)} files for pattern '{file_glob}'\")\n",
    "    # Load all matched files into a single Spark DataFrame.\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv([str(path) for path in matches])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Build combined DataFrames for each police dataset family.\n",
    "police_outcomes_df = load_police_dataset(\"*-metropolitan-outcomes.csv\")\n",
    "police_stop_search_df = load_police_dataset(\"*-metropolitan-stop-and-search.csv\")\n",
    "police_street_df = load_police_dataset(\"*-metropolitan-street.csv\")\n",
    "\n",
    "# Register temp views for downstream Spark SQL operations.\n",
    "police_outcomes_df.createOrReplaceTempView(\"police_outcomes\")\n",
    "police_stop_search_df.createOrReplaceTempView(\"police_stop_and_search\")\n",
    "police_street_df.createOrReplaceTempView(\"police_street\")\n",
    "\n",
    "# Print simple row counts for a quick sanity check.\n",
    "print(\"Combined police outcomes rows:\", police_outcomes_df.count())\n",
    "print(\"Combined police stop and search rows:\", police_stop_search_df.count())\n",
    "print(\"Combined police street rows:\", police_street_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b5cb4",
   "metadata": {},
   "source": [
    "#### 3.5.2. Police Outcomes Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47d242",
   "metadata": {},
   "source": [
    "##### 3.5.2.1. Police Outcomes Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Outcomes Schema:\")\n",
    "police_outcomes_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2a3ce",
   "metadata": {},
   "source": [
    "##### 3.5.2.2. Police Outcomes Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_outcomes_df.orderBy(\"Month\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_outcomes_df.orderBy(\"Month\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f545a3",
   "metadata": {},
   "source": [
    "##### 3.5.2.3. Police Outcomes Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_outcomes_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a2a8d",
   "metadata": {},
   "source": [
    "##### 3.5.2.4. Fill missing data with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_outcomes_df with None\n",
    "police_outcomes_df = police_outcomes_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_outcomes = [\n",
    "    f.name for f in police_outcomes_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_outcomes:\n",
    "    police_outcomes_df = police_outcomes_df.fillna(0.0, subset=numeric_cols_outcomes)\n",
    "\n",
    "police_outcomes_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6de0a3",
   "metadata": {},
   "source": [
    "#### 3.5.3. Police Stop and Search Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c866e9",
   "metadata": {},
   "source": [
    "##### 3.5.3.1. Police Stop and Search Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Stop and Search Schema:\")\n",
    "police_stop_search_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0820c9",
   "metadata": {},
   "source": [
    "##### 3.5.3.2. Police Stop and Search Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7056b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_stop_search_df.orderBy(\"Date\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_stop_search_df.orderBy(\"Date\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d711b",
   "metadata": {},
   "source": [
    "##### 3.5.3.3. Police Stop and Search Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_stop_search_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc3519",
   "metadata": {},
   "source": [
    "##### 3.5.3.4. Fill missing data with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa306f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_stop_search_df with None\n",
    "police_stop_search_df = police_stop_search_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_stop = [\n",
    "    f.name for f in police_stop_search_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_stop:\n",
    "    police_stop_search_df = police_stop_search_df.fillna(0.0, subset=numeric_cols_stop)\n",
    "\n",
    "police_stop_search_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7f1d3",
   "metadata": {},
   "source": [
    "#### 3.5.4. Police Street Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7b8a5",
   "metadata": {},
   "source": [
    "##### 3.5.4.1. Police Street Schema Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Police Stop and Search Schema:\")\n",
    "police_street_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b95ee",
   "metadata": {},
   "source": [
    "##### 3.5.4.2. Police Street Data Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Records\")\n",
    "police_street_df.orderBy(\"Month\").show(5)\n",
    "\n",
    "print(\"Last 5 Records\")\n",
    "police_street_df.orderBy(\"Month\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28343cf",
   "metadata": {},
   "source": [
    "##### 3.5.4.3. Police Street Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_street_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbf8ba",
   "metadata": {},
   "source": [
    "##### 3.5.4.4. Fill missing data with readable placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values in police_street_df with None\n",
    "police_street_df = police_street_df.fillna(\"None\")\n",
    "\n",
    "# Detect numeric columns automatically\n",
    "numeric_cols_street = [\n",
    "    f.name for f in police_street_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType)\n",
    "]\n",
    "\n",
    "# Fill all numeric columns with 0.0\n",
    "if numeric_cols_street:\n",
    "    police_street_df = police_street_df.fillna(0.0, subset=numeric_cols_street)\n",
    "\n",
    "police_street_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28eaa9f",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095b53c",
   "metadata": {},
   "source": [
    "### 4.0. Create Folders for Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Police-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Income-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Population-Data\", exist_ok=True)\n",
    "os.makedirs(\"Datasets/Cleaned-Data/Map-Data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff9e87",
   "metadata": {},
   "source": [
    "### 4.1. Transform Cleaned Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d67c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa2db3",
   "metadata": {},
   "source": [
    "#### 4.1.1. Select only the required columns from clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80256bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df = total_income_df.select(\n",
    "    \"MSOA code\",\n",
    "    \"MSOA name\",\n",
    "    \"Total annual income (Â£)\"\n",
    ")\n",
    "\n",
    "selected_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50954384",
   "metadata": {},
   "source": [
    "#### 4.1.2. Standardize Colomn Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_income_df = simplify_column_names(selected_income_df)\n",
    "selected_income_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622024d3",
   "metadata": {},
   "source": [
    "#### 4.1.3. Verify Income Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667f30b",
   "metadata": {},
   "source": [
    "#### 4.1.3. Save the cleaned income data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1875a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_income_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Income-Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_income_df = selected_income_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec819ae1",
   "metadata": {},
   "source": [
    "### 4.2. Transform Cleaned Population Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd644e0f",
   "metadata": {},
   "source": [
    "#### 4.2.1. Display the Population DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2022_df.show(5)\n",
    "population_2023_df.show(5)\n",
    "population_2024_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd92b4",
   "metadata": {},
   "source": [
    "#### 4.2.2. Select Required Columns from Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_population_columns(population_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return population_df.select(\n",
    "        \"LSOA 2021 Code\",\n",
    "        \"LSOA 2021 Name\",\n",
    "        \"Total\"\n",
    "\n",
    "    )\n",
    "\n",
    "selected_population_2022_df = select_population_columns(population_2022_df)\n",
    "selected_population_2023_df = select_population_columns(population_2023_df)\n",
    "selected_population_2024_df = select_population_columns(population_2024_df)\n",
    "\n",
    "selected_population_2022_df.show(5)\n",
    "selected_population_2023_df.show(5)\n",
    "selected_population_2024_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d118dc",
   "metadata": {},
   "source": [
    "#### 4.2.3. Standardize Population Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_population_2022_df = simplify_column_names(selected_population_2022_df)\n",
    "selected_population_2022_df.show(5)\n",
    "\n",
    "selected_population_2023_df = simplify_column_names(selected_population_2023_df)\n",
    "selected_population_2023_df.show(5)\n",
    "\n",
    "selected_population_2024_df = simplify_column_names(selected_population_2024_df)\n",
    "selected_population_2024_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10cd90",
   "metadata": {},
   "source": [
    "#### 4.2.4. Verify Population Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_population_2022_df.printSchema()\n",
    "selected_population_2023_df.printSchema()\n",
    "selected_population_2024_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c280fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Add year column to each population dataframe\n",
    "pop_2022_with_year = selected_population_2022_df.withColumn(\"year\", lit(2022))\n",
    "pop_2023_with_year = selected_population_2023_df.withColumn(\"year\", lit(2023))\n",
    "pop_2024_with_year = selected_population_2024_df.withColumn(\"year\", lit(2024))\n",
    "\n",
    "# Union all population dataframes\n",
    "combined_population_df = pop_2022_with_year.union(pop_2023_with_year).union(pop_2024_with_year)\n",
    "\n",
    "combined_population_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f412ef7",
   "metadata": {},
   "source": [
    "#### 4.2.5. Save Cleaned Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "selected_population_2022_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2022\")\n",
    "selected_population_2023_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2023\")\n",
    "selected_population_2024_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/2024\")\n",
    "combined_population_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Population-Data/Combined\")                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2022_df = selected_population_2022_df\n",
    "population_2023_df = selected_population_2023_df\n",
    "population_2024_df = selected_population_2024_df\n",
    "population_df = combined_population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32d0f4",
   "metadata": {},
   "source": [
    "### 4.3. Transform Cleaned Map Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f77175",
   "metadata": {},
   "source": [
    "#### 4.3.1. Display the Map DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f509fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lsoa_df.show(5)\n",
    "map_msoa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100337e6",
   "metadata": {},
   "source": [
    "#### 4.3.2. Select Required Columns from LSOA Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381825f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lsoa_columns(map_lsoa_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return map_lsoa_df.select(\n",
    "        \"LSOA21CD\",\n",
    "        \"LSOA21NM\",\n",
    "        \"LAT\",\n",
    "        \"LONG\"\n",
    "    )\n",
    "\n",
    "selected_map_lsoa_df = select_lsoa_columns(map_lsoa_df)\n",
    "\n",
    "selected_map_lsoa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d615fd",
   "metadata": {},
   "source": [
    "#### 4.3.3. Select Required Columns from MSOA Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_msoa_columns(map_msoa_df):\n",
    "    # Select only the required columns from the population DataFrame\n",
    "    return map_msoa_df.select(\n",
    "        \"MSOA21CD\",\n",
    "        \"MSOA21NM\",\n",
    "        \"LAT\",\n",
    "        \"LONG\"\n",
    "    )\n",
    "\n",
    "selected_map_msoa_df = select_msoa_columns(map_msoa_df)\n",
    "\n",
    "selected_map_msoa_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5adeb",
   "metadata": {},
   "source": [
    "#### 4.3.4. Standardize Map Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "selected_map_lsoa_df = simplify_column_names(selected_map_lsoa_df)\n",
    "selected_map_lsoa_df.show(5)\n",
    "\n",
    "selected_map_msoa_df = simplify_column_names(selected_map_msoa_df)\n",
    "selected_map_msoa_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81d1ff",
   "metadata": {},
   "source": [
    "#### 4.3.5. Verify Map Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_map_lsoa_df.printSchema()\n",
    "selected_map_msoa_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9841e0d",
   "metadata": {},
   "source": [
    "#### 4.3.6. Save Cleaned Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "selected_map_lsoa_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Map-Data/lsoa\")\n",
    "selected_map_msoa_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Map-Data/msoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd14e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_msoa_df = selected_map_msoa_df\n",
    "map_lsoa_df = selected_map_lsoa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c8880",
   "metadata": {},
   "source": [
    "### 4.4. Transform Cleaned Police Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1682e",
   "metadata": {},
   "source": [
    "#### 4.4.1. Display the Police DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a317273",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_outcomes_df.show(5)\n",
    "police_stop_search_df.show(5)\n",
    "police_street_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0223",
   "metadata": {},
   "source": [
    "#### 4.4.2. Standardize Police Data Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_cols = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "police_outcomes_df = simplify_column_names(police_outcomes_df)\n",
    "police_outcomes_df.show(5)\n",
    "\n",
    "police_stop_search_df = simplify_column_names(police_stop_search_df)\n",
    "police_stop_search_df.show(5)\n",
    "\n",
    "police_street_df = simplify_column_names(police_street_df)\n",
    "police_street_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6e0aa",
   "metadata": {},
   "source": [
    "#### 4.4.3. Save Police Data as CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab46335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned income data\n",
    "# police_stop_search_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/stop-search\")\n",
    "# police_outcomes_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/outcomes\")\n",
    "# police_street_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"Datasets/Cleaned-Data/Police-Data/street\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119baca",
   "metadata": {},
   "source": [
    "#### 4.4.4. Save Police Data as Parquet with Snappy Compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62230e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stop & search data as Parquet\n",
    "police_stop_search_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/stop-search-parquet\")\n",
    "\n",
    "# Save outcomes data as Parquet\n",
    "police_outcomes_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/outcomes-parquet\")\n",
    "\n",
    "# Save street data as Parquet\n",
    "police_street_df.write.mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .parquet(\"Datasets/Cleaned-Data/Police-Data/street-parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9003f6",
   "metadata": {},
   "source": [
    "## 5. Data Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ffb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, col, count\n",
    "from pyspark.sql.functions import lit, avg, sum as spark_sum\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c60b26",
   "metadata": {},
   "source": [
    "### 5.1. Street Crime Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2273458",
   "metadata": {},
   "source": [
    "#### 5.1.1. Total Street Crimes by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69dfe8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Crimes by Year:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 567:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|total_crimes|\n",
      "+----+------------+\n",
      "|2022|      284383|\n",
      "|2023|     1135031|\n",
      "|2024|     1139329|\n",
      "|2025|      856701|\n",
      "+----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "police_street_df.createOrReplaceTempView(\"police_street\")\n",
    "\n",
    "crimes_by_year = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  YEAR(TO_DATE(month, 'yyyy-MM')) AS year,\n",
    "  COUNT(*) AS total_crimes\n",
    "FROM police_street\n",
    "WHERE month IS NOT NULL\n",
    "GROUP BY YEAR(TO_DATE(month, 'yyyy-MM'))\n",
    "ORDER BY year\n",
    "\"\"\")\n",
    "\n",
    "print(\"Total Crimes by Year:\")\n",
    "crimes_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9057644",
   "metadata": {},
   "source": [
    "#### 5.1.2. Total Street Crimes by Year with Cumulative Totals and Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e917a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Crimes by Year with Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/13 08:49:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------+-------------------+\n",
      "|year|total_crimes|cumulative_crimes|percentage_of_total|\n",
      "+----+------------+-----------------+-------------------+\n",
      "|2022|      284383|           284383|               8.33|\n",
      "|2023|     1135031|          1419414|              33.23|\n",
      "|2024|     1139329|          2558743|              33.36|\n",
      "|2025|      856701|          3415444|              25.08|\n",
      "+----+------------+-----------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "crimes_by_year.createOrReplaceTempView(\"crimes_by_year\")\n",
    "\n",
    "crimes_by_year_with_analysis = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  year,\n",
    "  total_crimes,\n",
    "  SUM(total_crimes) OVER (\n",
    "    ORDER BY year\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "  ) AS cumulative_crimes,\n",
    "  ROUND(\n",
    "    (total_crimes / SUM(total_crimes) OVER ()) * 100,\n",
    "    2\n",
    "  ) AS percentage_of_total\n",
    "FROM crimes_by_year\n",
    "ORDER BY year\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTotal Crimes by Year with Analysis:\")\n",
    "crimes_by_year_with_analysis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a907e4d",
   "metadata": {},
   "source": [
    "#### 5.1.3. Total Outcomes by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d97746b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Outcomes by Year:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 582:========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|year|total_outcomes|\n",
      "+----+--------------+\n",
      "|2022|         91647|\n",
      "|2023|        996983|\n",
      "|2024|       1027756|\n",
      "|2025|        678038|\n",
      "+----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "police_outcomes_df.createOrReplaceTempView(\"police_outcomes\")\n",
    "\n",
    "outcomes_by_year = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  YEAR(TO_DATE(month, 'yyyy-MM')) AS year,\n",
    "  COUNT(*) AS total_outcomes\n",
    "FROM police_outcomes\n",
    "WHERE month IS NOT NULL\n",
    "GROUP BY YEAR(TO_DATE(month, 'yyyy-MM'))\n",
    "ORDER BY year\n",
    "\"\"\")\n",
    "\n",
    "print(\"Total Outcomes by Year:\")\n",
    "outcomes_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d8e75",
   "metadata": {},
   "source": [
    "#### 5.1.4. Total Outcomes by Year with Cumulative Totals and Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "802453d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Outcomes by Year with Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/13 08:49:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 585:========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-------------------+-------------------+\n",
      "|year|total_outcomes|cumulative_outcomes|percentage_of_total|\n",
      "+----+--------------+-------------------+-------------------+\n",
      "|2022|         91647|              91647|               3.28|\n",
      "|2023|        996983|            1088630|              35.68|\n",
      "|2024|       1027756|            2116386|              36.78|\n",
      "|2025|        678038|            2794424|              24.26|\n",
      "+----+--------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/12/13 08:49:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "outcomes_by_year.createOrReplaceTempView(\"outcomes_by_year\")\n",
    "\n",
    "outcomes_by_year_with_analysis = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  year,\n",
    "  total_outcomes,\n",
    "  SUM(total_outcomes) OVER (\n",
    "    ORDER BY year\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "  ) AS cumulative_outcomes,\n",
    "  ROUND(\n",
    "    (total_outcomes / SUM(total_outcomes) OVER ()) * 100,\n",
    "    2\n",
    "  ) AS percentage_of_total\n",
    "FROM outcomes_by_year\n",
    "ORDER BY year\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTotal Outcomes by Year with Analysis:\")\n",
    "outcomes_by_year_with_analysis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1ad37",
   "metadata": {},
   "source": [
    "#### 5.1.5. Outcomes vs Street Crimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd7c44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcomes vs Crimes Comparison:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 598:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+--------------+--------------+\n",
      "|year|total_crimes|total_outcomes|outcome_rate_%|\n",
      "+----+------------+--------------+--------------+\n",
      "|2022|      284383|         91647|         32.23|\n",
      "|2023|     1135031|        996983|         87.84|\n",
      "|2024|     1139329|       1027756|         90.21|\n",
      "|2025|      856701|        678038|         79.15|\n",
      "+----+------------+--------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutcomes vs Crimes Comparison:\")\n",
    "\n",
    "# Ensure both DataFrames are available as SQL views\n",
    "crimes_by_year.createOrReplaceTempView(\"crimes_by_year\")\n",
    "outcomes_by_year.createOrReplaceTempView(\"outcomes_by_year\")\n",
    "\n",
    "comparison_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  c.year AS year,\n",
    "  c.total_crimes,\n",
    "  o.total_outcomes,\n",
    "  ROUND(\n",
    "    CASE\n",
    "      WHEN c.total_crimes > 0 THEN (o.total_outcomes / c.total_crimes) * 100\n",
    "      ELSE 0\n",
    "    END,\n",
    "    2\n",
    "  ) AS `outcome_rate_%`\n",
    "FROM crimes_by_year c\n",
    "INNER JOIN outcomes_by_year o\n",
    "  ON c.year = o.year\n",
    "ORDER BY year\n",
    "\"\"\")\n",
    "\n",
    "comparison_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c6bd9",
   "metadata": {},
   "source": [
    "#### 5.1.6. Avarage Population by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c40d3392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Population by LSOA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 623:=============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-----------------+\n",
      "|lsoa_2021_code|lsoa_2021_name    |avg_population   |\n",
      "+--------------+------------------+-----------------+\n",
      "|E01028521     |Oxford 008A       |9817.666666666666|\n",
      "|E01035514     |Cambridge 005H    |8611.333333333334|\n",
      "|E01033617     |Birmingham 050F   |6959.0           |\n",
      "|E01013378     |York 023B         |6785.666666666667|\n",
      "|E01034493     |County Durham 030H|6463.0           |\n",
      "+--------------+------------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "population_df.createOrReplaceTempView(\"population\")\n",
    "\n",
    "avg_population_by_lsoa = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  lsoa_2021_code,\n",
    "  lsoa_2021_name,\n",
    "  AVG(try_cast(regexp_replace(cast(total AS string), ',', '') AS double)) AS avg_population\n",
    "FROM population\n",
    "GROUP BY lsoa_2021_code, lsoa_2021_name\n",
    "ORDER BY avg_population DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nAverage Population by LSOA:\")\n",
    "avg_population_by_lsoa.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5099c7",
   "metadata": {},
   "source": [
    "#### 5.1.7. Top 5 Street Crimes by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2ae817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Locations by Crime Count:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 626:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------------+\n",
      "|lsoa_code|lsoa_name       |total_crimes|\n",
      "+---------+----------------+------------+\n",
      "|E01035716|Westminster 013G|36888       |\n",
      "|E01004763|Westminster 013B|33895       |\n",
      "|E01004734|Westminster 018A|33164       |\n",
      "|None     |None            |31291       |\n",
      "|E01004736|Westminster 018C|18857       |\n",
      "+---------+----------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "police_street_df.createOrReplaceTempView(\"police_street\")\n",
    "\n",
    "crimes_by_lsoa = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  lsoa_code,\n",
    "  lsoa_name,\n",
    "  COUNT(*) AS total_crimes\n",
    "FROM police_street\n",
    "GROUP BY lsoa_code, lsoa_name\n",
    "ORDER BY total_crimes DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTop 5 Locations by Crime Count:\")\n",
    "crimes_by_lsoa.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725546c2",
   "metadata": {},
   "source": [
    "#### 5.1.8. Top 5 Locations by Street Crime with Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c5beb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Locations by Crime with Population Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------------+------------------+----------------------+\n",
      "|lsoa_code|lsoa_name       |total_crimes|avg_population    |crimes_per_1000_people|\n",
      "+---------+----------------+------------+------------------+----------------------+\n",
      "|E01035716|Westminster 013G|36888       |2270.0            |16250.22              |\n",
      "|E01004763|Westminster 013B|33895       |2187.3333333333335|15496.04              |\n",
      "|E01004734|Westminster 018A|33164       |1806.0            |18363.23              |\n",
      "|None     |None            |31291       |NULL              |0.0                   |\n",
      "|E01004736|Westminster 018C|18857       |1609.0            |11719.7               |\n",
      "+---------+----------------+------------+------------------+----------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "crimes_by_lsoa.createOrReplaceTempView(\"crimes_by_lsoa\")\n",
    "avg_population_by_lsoa.createOrReplaceTempView(\"avg_population_by_lsoa\")\n",
    "\n",
    "crime_population_analysis = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  c.lsoa_code,\n",
    "  c.lsoa_name,\n",
    "  c.total_crimes,\n",
    "  p.avg_population,\n",
    "  CASE\n",
    "    WHEN p.avg_population IS NOT NULL AND p.avg_population > 0\n",
    "      THEN ROUND((c.total_crimes / p.avg_population) * 1000, 2)\n",
    "    ELSE 0\n",
    "  END AS crimes_per_1000_people\n",
    "FROM crimes_by_lsoa c\n",
    "LEFT JOIN avg_population_by_lsoa p\n",
    "  ON c.lsoa_code = p.lsoa_2021_code\n",
    "ORDER BY c.total_crimes DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTop 5 Locations by Crime with Population Analysis:\")\n",
    "crime_population_analysis.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ed097",
   "metadata": {},
   "source": [
    "#### 5.1.9. Top 5 by Crime Rate Per Capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5ad36c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Locations by Crime Rate (per 1000 people):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------------+------------------+----------------------+\n",
      "|lsoa_code|lsoa_name       |total_crimes|avg_population    |crimes_per_1000_people|\n",
      "+---------+----------------+------------+------------------+----------------------+\n",
      "|E01004734|Westminster 018A|33164       |1806.0            |18363.23              |\n",
      "|E01035716|Westminster 013G|36888       |2270.0            |16250.22              |\n",
      "|E01004763|Westminster 013B|33895       |2187.3333333333335|15496.04              |\n",
      "|E01004736|Westminster 018C|18857       |1609.0            |11719.7               |\n",
      "|E01004714|Westminster 011B|12948       |1723.0            |7514.8                |\n",
      "+---------+----------------+------------+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 5 Locations by Crime Rate (per 1000 people):\")\n",
    "\n",
    "crime_population_analysis.createOrReplaceTempView(\"crime_population_analysis\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  lsoa_code,\n",
    "  lsoa_name,\n",
    "  total_crimes,\n",
    "  avg_population,\n",
    "  crimes_per_1000_people\n",
    "FROM crime_population_analysis\n",
    "ORDER BY crimes_per_1000_people DESC\n",
    "LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ed487",
   "metadata": {},
   "source": [
    "### 5.2. Stop and Search Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0775f",
   "metadata": {},
   "source": [
    "#### 5.2.1. Total Stop and Search by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_search_by_year = police_stop_search_df \\\n",
    "    .withColumn(\"year\", F.year(F.to_date(col(\"date\"), \"yyyy-MM-dd\"))) \\\n",
    "    .groupBy(\"year\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_stop_searches\")) \\\n",
    "    .orderBy(\"year\")\n",
    "\n",
    "stop_search_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde012eb",
   "metadata": {},
   "source": [
    "#### 5.2.1. Total Stop and Search by Year with Cumulative Totals and Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(\"year\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "stop_search_analysis = stop_search_by_year \\\n",
    "    .withColumn(\"cumulative_searches\", F.sum(\"total_stop_searches\").over(window_spec)) \\\n",
    "    .withColumn(\"percentage_of_total\", \n",
    "                F.round((col(\"total_stop_searches\") / F.sum(\"total_stop_searches\").over(Window.partitionBy())) * 100, 2))\n",
    "\n",
    "print(\"\\nStop and Search by Year with Analysis:\")\n",
    "stop_search_analysis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d219c9",
   "metadata": {},
   "source": [
    "#### 5.2.3. Total searches by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_search_by_type_summary = police_stop_search_df \\\n",
    "    .groupBy(\"type\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "print(\"\\nSummary by Type:\")\n",
    "stop_search_by_type_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34dc44",
   "metadata": {},
   "source": [
    "#### 5.2.4. Stop and Search by Type/Object of Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_search_by_type = police_stop_search_df \\\n",
    "    .groupBy(\"type\", \"object_of_search\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "print(\"\\nTop 10 Search Types and Objects:\")\n",
    "stop_search_by_type.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb752ee",
   "metadata": {},
   "source": [
    "#### 5.2.5. Stop and Searches By Age Range only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_search_by_age = police_stop_search_df \\\n",
    "    .groupBy(\"age_range\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "print(\"\\nSummary by Age Range:\")\n",
    "stop_search_by_age.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11bf90",
   "metadata": {},
   "source": [
    "#### 5.2.6. Stop and Search by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_search_by_gender = police_stop_search_df \\\n",
    "    .groupBy(\"gender\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "print(\"\\nSummary by Gender:\")\n",
    "stop_search_by_gender.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2eae0b",
   "metadata": {},
   "source": [
    "#### 5.2.7. Stop and Search by Age Range and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e3988056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop and Search by Age Range and Gender:\n",
      "+---------+------+--------------+\n",
      "|age_range|gender|total_searches|\n",
      "+---------+------+--------------+\n",
      "|18-24    |Male  |89135         |\n",
      "|over 34  |Male  |77731         |\n",
      "|25-34    |Male  |71030         |\n",
      "|10-17    |Male  |55622         |\n",
      "|None     |Male  |42077         |\n",
      "|over 34  |Female|12616         |\n",
      "|25-34    |Female|7453          |\n",
      "|18-24    |Female|6636          |\n",
      "|18-24    |Other |4454          |\n",
      "|None     |None  |4118          |\n",
      "|18-24    |None  |4046          |\n",
      "|10-17    |Female|3944          |\n",
      "|None     |Female|3406          |\n",
      "|25-34    |Other |3383          |\n",
      "|over 34  |Other |3268          |\n",
      "|25-34    |None  |3213          |\n",
      "|over 34  |None  |3076          |\n",
      "|None     |Other |2641          |\n",
      "|10-17    |Other |2513          |\n",
      "|10-17    |None  |2088          |\n",
      "+---------+------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop and Search by Age Range and Gender:\n",
      "+---------+------+--------------+\n",
      "|age_range|gender|total_searches|\n",
      "+---------+------+--------------+\n",
      "|18-24    |Male  |89135         |\n",
      "|over 34  |Male  |77731         |\n",
      "|25-34    |Male  |71030         |\n",
      "|10-17    |Male  |55622         |\n",
      "|None     |Male  |42077         |\n",
      "|over 34  |Female|12616         |\n",
      "|25-34    |Female|7453          |\n",
      "|18-24    |Female|6636          |\n",
      "|18-24    |Other |4454          |\n",
      "|None     |None  |4118          |\n",
      "|18-24    |None  |4046          |\n",
      "|10-17    |Female|3944          |\n",
      "|None     |Female|3406          |\n",
      "|25-34    |Other |3383          |\n",
      "|over 34  |Other |3268          |\n",
      "|25-34    |None  |3213          |\n",
      "|over 34  |None  |3076          |\n",
      "|None     |Other |2641          |\n",
      "|10-17    |Other |2513          |\n",
      "|10-17    |None  |2088          |\n",
      "+---------+------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stop_search_by_age_gender = police_stop_search_df \\\n",
    "    .groupBy(\"age_range\", \"gender\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "print(\"\\nStop and Search by Age Range and Gender:\")\n",
    "stop_search_by_age_gender.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffb8ff",
   "metadata": {},
   "source": [
    "#### 5.2.8. Top Outcomes of Stop and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b403915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Outcomes with Percentages:\n",
      "+-------------------------------+--------------+----------+\n",
      "|outcome                        |total_searches|percentage|\n",
      "+-------------------------------+--------------+----------+\n",
      "|A no further action disposal   |277204        |68.81     |\n",
      "|Arrest                         |66418         |16.49     |\n",
      "|Community resolution           |39919         |9.91      |\n",
      "|Penalty Notice for Disorder    |11446         |2.84      |\n",
      "|Summons / charged by post      |5563          |1.38      |\n",
      "|Caution (simple or conditional)|2291          |0.57      |\n",
      "|None                           |7             |0.0       |\n",
      "+-------------------------------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_search_by_outcome = police_stop_search_df \\\n",
    "    .groupBy(\"outcome\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_searches\")) \\\n",
    "    .orderBy(F.desc(\"total_searches\"))\n",
    "\n",
    "# Calculate outcome percentages\n",
    "total_searches = police_stop_search_df.count()\n",
    "stop_search_outcome_pct = stop_search_by_outcome \\\n",
    "    .withColumn(\"percentage\", F.round((col(\"total_searches\") / total_searches) * 100, 2))\n",
    "\n",
    "print(\"\\nTop Outcomes with Percentages:\")\n",
    "stop_search_outcome_pct.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073d989",
   "metadata": {},
   "source": [
    "Income data vs Msao Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e9f1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------+-----------------------+--------+--------+\n",
      "|msoa_code|msoa_name                 |total_annual_income_gbp|lat     |long    |\n",
      "+---------+--------------------------+-----------------------+--------+--------+\n",
      "|E02000931|Wandsworth 009            |108100.0               |51.4606 |-0.15622|\n",
      "|E02000001|City of London 001        |101800.0               |51.51562|-0.09349|\n",
      "|E02000890|Tower Hamlets 027         |96600.0                |51.50671|-0.07076|\n",
      "|E02000937|Wandsworth 015            |94000.0                |51.45231|-0.16795|\n",
      "|E02000949|Wandsworth 027            |93800.0                |51.44086|-0.16982|\n",
      "|E02006334|Elmbridge 018             |93500.0                |51.32983|-0.36945|\n",
      "|E02000809|Southwark 003             |92800.0                |NULL    |NULL    |\n",
      "|E02006325|Elmbridge 009             |92100.0                |51.3752 |-0.33779|\n",
      "|E02000939|Wandsworth 017            |91600.0                |51.45308|-0.157  |\n",
      "|E02000592|Kensington and Chelsea 016|91100.0                |51.49196|-0.1793 |\n",
      "+---------+--------------------------+-----------------------+--------+--------+\n",
      "\n",
      "+---------+----------------------------+-----------------------+--------+--------+\n",
      "|msoa_code|msoa_name                   |total_annual_income_gbp|lat     |long    |\n",
      "+---------+----------------------------+-----------------------+--------+--------+\n",
      "|E02002727|North East Lincolnshire 002 |22200.0                |53.5755 |-0.06559|\n",
      "|E02002686|East Riding of Yorkshire 003|23800.0                |54.08331|-0.22332|\n",
      "|E02002496|Middlesbrough 001           |24900.0                |54.57778|-1.23137|\n",
      "|E02002280|Kirklees 010                |25100.0                |53.71508|-1.63979|\n",
      "|E02002688|East Riding of Yorkshire 005|25200.0                |54.08002|-0.19879|\n",
      "|E02002234|Bradford 052                |25400.0                |53.77618|-1.70922|\n",
      "|E02002642|Blackpool 010               |25600.0                |53.81551|-3.04893|\n",
      "|E02002645|Blackpool 013               |25700.0                |53.80222|-3.05033|\n",
      "|E02001680|Sheffield 070               |25700.0                |53.32336|-1.46909|\n",
      "|E02005709|Northumberland 022          |25900.0                |55.12826|-1.53533|\n",
      "+---------+----------------------------+-----------------------+--------+--------+\n",
      "\n",
      "+---------------------------+\n",
      "|avg_total_annual_income_gbp|\n",
      "+---------------------------+\n",
      "|          46445.54922927371|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top / Bottom income MSOAs + overall average (join income to MSOA map)\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "income_col = \"total_annual_income_(Â£)\"\n",
    "\n",
    "income_geo_df = (\n",
    "    total_income_df\n",
    "    .join(\n",
    "        map_msoa_df.select(\"msoa21cd\", \"msoa21nm\", \"lat\", \"long\"),\n",
    "        total_income_df[\"msoa_code\"] == F.col(\"msoa21cd\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"msoa_code\").alias(\"msoa_code\"),\n",
    "        F.coalesce(F.col(\"msoa_name\"), F.col(\"msoa21nm\")).alias(\"msoa_name\"),\n",
    "        F.col(income_col).cast(\"double\").alias(\"total_annual_income_gbp\"),\n",
    "        F.col(\"lat\").cast(\"double\").alias(\"lat\"),\n",
    "        F.col(\"long\").cast(\"double\").alias(\"long\"),\n",
    "    )\n",
    "    .dropna(subset=[\"total_annual_income_gbp\"])\n",
    ")\n",
    "\n",
    "income_geo_df.createOrReplaceTempView(\"income_geo\")\n",
    "\n",
    "# Top 10 highest-income locations\n",
    "spark.sql(\"\"\"\n",
    "SELECT msoa_code, msoa_name, total_annual_income_gbp, lat, long\n",
    "FROM income_geo\n",
    "ORDER BY total_annual_income_gbp DESC\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "# Bottom 10 lowest-income locations\n",
    "spark.sql(\"\"\"\n",
    "SELECT msoa_code, msoa_name, total_annual_income_gbp, lat, long\n",
    "FROM income_geo\n",
    "ORDER BY total_annual_income_gbp ASC\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "# Average income across all MSOAs\n",
    "spark.sql(\"\"\"\n",
    "SELECT AVG(total_annual_income_gbp) AS avg_total_annual_income_gbp\n",
    "FROM income_geo\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
